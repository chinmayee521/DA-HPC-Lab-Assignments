{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HPC_VectorAdd_MatMul.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOxkfMNrrcNT"
      },
      "source": [
        "#Name- Chinmayee Taralkar\n",
        "#Rollno - BECOB262\n",
        "#HPC- Matrix multiplication and vector addition codes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NwtrGDklESR"
      },
      "source": [
        "Vector and Matrix Operations- Design parallel algorithm to\n",
        "1. Add two large vectors,\n",
        "2. Multiply two N Ã— N arrays using n 2 processors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4iCMkXIJYpk",
        "outputId": "3b5b0748-016c-4edb-87df-894b4fd7e403"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX8TJ_vLJ34S",
        "outputId": "02e8e7c1-14ba-49c9-8464-eb8dc84da0ce"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-tu3luv3h\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-tu3luv3h\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=6f8a66b4148ff088fc17adb702d4d6f6cad83526d3fee241f09423ef5d693f35\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-03g9ini0/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBSLHPNyKkE0",
        "outputId": "77a58967-5f96-46b2-af9f-4ba3b8b2b331"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIitu2Kqjxaz"
      },
      "source": [
        "## Matrix Multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chAUOypkKtZh",
        "outputId": "a678ceb7-450d-4d24-afc3-3671f578da87"
      },
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#define N 4\n",
        "#define TPB 2\n",
        "\n",
        "__global__ void matrixMultiplication(int *a, int *b, int *c, int n)\n",
        "{\n",
        "\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int sum = 0;\n",
        "    int i;\n",
        "    if (row < n && col < n) {\n",
        "    for( i=0; i<n ;i++)\n",
        "    {\n",
        "    \tsum += a[row *n +i] *  b[i * n+ col];\n",
        "    }\n",
        "    c[row *N +col]=sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "  int *h_a, *h_b, *h_c;\n",
        "  int *d_a, *d_b, *d_c;\n",
        "\n",
        "  int size=sizeof(int)*N*N;\n",
        "  cudaEvent_t start,end;\n",
        "  float time=0;\n",
        "  h_a=(int*)malloc(size);\n",
        "  h_b=(int*)malloc(size);\n",
        "  h_c=(int*)malloc(size);\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&end);\n",
        "  cudaEventRecord(start);\n",
        "\n",
        "  cudaMalloc(&d_a, size);\n",
        "  cudaMalloc(&d_b, size);\n",
        "  cudaMalloc(&d_c, size);\n",
        "\n",
        "  int i,j;\n",
        "\n",
        "  for (i = 0; i < N*N; i++)\n",
        "   {\n",
        "\n",
        " \t  h_a[i] = random() % N;\n",
        " \t  h_b[i] = random() % N;\n",
        "\n",
        "\n",
        "  }\n",
        "\n",
        "  printf(\"\\nMatrix A =>\\n\\n\");\n",
        "  for ( i = 0; i < N; i++)\n",
        "   {\n",
        " \tfor( j = 0;j<N; j++)\n",
        " \t{\n",
        " \t  printf(\"%d \",h_a[i*N + j]);\n",
        " \t}\n",
        " \tprintf(\"\\n\");\n",
        "   }\n",
        "\n",
        "  printf(\"\\nMatrix B =>\\n\\n\");\n",
        "   for ( i = 0; i < N; i++)\n",
        "    {\n",
        "  \tfor( j = 0;j<N; j++)\n",
        "  \t{\n",
        "  \t  printf(\"%d \",h_b[i*N + j]);\n",
        "  \t}\n",
        "  \tprintf(\"\\n\");\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "  cudaMemcpy( d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy( d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  int BLOCK_SIZE=N / TPB;\n",
        "\n",
        "  dim3 GridSize(BLOCK_SIZE, BLOCK_SIZE);\n",
        "  dim3 BlockSize(TPB, TPB);\n",
        "\n",
        "  matrixMultiplication<<<GridSize,BlockSize>>>(d_a, d_b, d_c, N);\n",
        "\n",
        "  cudaMemcpy( h_c, d_c, size, cudaMemcpyDeviceToHost );\n",
        "  cudaEventRecord(end);\n",
        "  cudaEventSynchronize(end);\n",
        "  cudaEventElapsedTime(&time,start,end);\n",
        "  printf(\"\\nMatrix C =>\\n\\n\");\n",
        "\n",
        "  for ( i = 0; i < N; i++)\n",
        "  {\n",
        "\tfor( j = 0;j<N; j++)\n",
        "\t{\n",
        "\t  printf(\"%d \",h_c[i*N + j]);\n",
        "\t}\n",
        "\tprintf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  printf(\"Time taken to perform %d by %d matrix mul is: %lf ms\",N,N,time);\n",
        "\n",
        "   cudaFree(d_a);\n",
        "   cudaFree(d_b);\n",
        "   cudaFree(d_c);\n",
        "\n",
        "   free(h_a);\n",
        "   free(h_b);\n",
        "   free(h_c);\n",
        "\n",
        "   return 0;\n",
        "\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Matrix A =>\n",
            "\n",
            "3 1 1 2 \n",
            "1 2 2 3 \n",
            "0 0 3 3 \n",
            "2 2 3 1 \n",
            "\n",
            "Matrix B =>\n",
            "\n",
            "2 3 3 0 \n",
            "1 3 3 2 \n",
            "2 0 0 1 \n",
            "2 3 3 2 \n",
            "\n",
            "Matrix C =>\n",
            "\n",
            "13 18 18 7 \n",
            "14 18 18 12 \n",
            "12 9 9 9 \n",
            "14 15 15 9 \n",
            "Time taken to perform 4 by 4 matrix mul is: 0.336640 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn5JU1DtrVC3"
      },
      "source": [
        "#Vector Addition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-k6tLt1rUg4",
        "outputId": "86373e11-e02c-4922-a0a5-6a1f78deeaa9"
      },
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        " \n",
        "// CUDA kernel. Each thread takes care of one element of c\n",
        "__global__ void vecAdd(double *a, double *b, double *c, int n)\n",
        "{\n",
        "    // Get our global thread ID\n",
        "    int id = blockIdx.x*blockDim.x+threadIdx.x;\n",
        " \n",
        "    // Make sure we do not go out of bounds\n",
        "    if (id < n)\n",
        "        c[id] = a[id] + b[id];\n",
        "}\n",
        " \n",
        "int main( int argc, char* argv[] )\n",
        "{\n",
        "    // Size of vectors\n",
        "    int n = 100000;\n",
        " \n",
        "    // Host input vectors\n",
        "    double *h_a;\n",
        "    double *h_b;\n",
        "    //Host output vector\n",
        "    double *h_c;\n",
        " \n",
        "    // Device input vectors\n",
        "    double *d_a;\n",
        "    double *d_b;\n",
        "    //Device output vector\n",
        "    double *d_c;\n",
        " \n",
        "    // Size, in bytes, of each vector\n",
        "    size_t bytes = n*sizeof(double);\n",
        " \n",
        "    // Allocate memory for each vector on host\n",
        "    h_a = (double*)malloc(bytes);\n",
        "    h_b = (double*)malloc(bytes);\n",
        "    h_c = (double*)malloc(bytes);\n",
        " \n",
        "    // Allocate memory for each vector on GPU\n",
        "    cudaMalloc(&d_a, bytes);\n",
        "    cudaMalloc(&d_b, bytes);\n",
        "    cudaMalloc(&d_c, bytes);\n",
        " \n",
        "    int i;\n",
        "    // Initialize vectors on host\n",
        "    for( i = 0; i < n; i++ ) {\n",
        "        h_a[i] = i;\n",
        "        h_b[i] = i;\n",
        "    }\n",
        " \n",
        "    // Copy host vectors to device\n",
        "    cudaMemcpy( d_a, h_a, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy( d_b, h_b, bytes, cudaMemcpyHostToDevice);\n",
        " \n",
        "    int blockSize, gridSize;\n",
        " \n",
        "    // Number of threads in each thread block\n",
        "    blockSize = 1024;\n",
        " \n",
        "    // Number of thread blocks in grid\n",
        "    gridSize = (int)ceil((float)n/blockSize);\n",
        " \n",
        "    // Execute the kernel\n",
        "    vecAdd<<<gridSize, blockSize>>>(d_a, d_b, d_c, n);\n",
        " \n",
        "    // Copy array back to host\n",
        "    cudaMemcpy( h_c, d_c, bytes, cudaMemcpyDeviceToHost );\n",
        " \n",
        "    // Sum up vector c and print result divided by n, this should equal 1 within error\n",
        "    double sum = 0;\n",
        "    for(i=0; i<n; i++)\n",
        "        sum += h_c[i];\n",
        "    printf(\"Sum: %f\\n\", sum/n);\n",
        " \n",
        "    // Release device memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        " \n",
        "    // Release host memory\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        " \n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sum: 99999.000000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}